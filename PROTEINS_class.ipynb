{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec222cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric.nn as gnn # note the difference from nn!\n",
    "from torch_geometric.nn import GCNConv, global_sort_pool # NOTE: global_sort_pool!!!\n",
    "from torch_geometric.utils import degree\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Conv1d, MaxPool1d, Linear, Dropout\n",
    "from torch_geometric.utils import remove_self_loops\n",
    "\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa1570eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Indegree(object):\n",
    "    r\"\"\"Adds the globally normalized node degree to the node features.\n",
    "    Args:\n",
    "        cat (bool, optional): If set to :obj:`False`, all existing node\n",
    "            features will be replaced. (default: :obj:`True`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, norm=True, max_value=None, cat=True):\n",
    "        self.norm = norm\n",
    "        self.max = max_value\n",
    "        self.cat = cat\n",
    "\n",
    "    def __call__(self, data):\n",
    "        col, x = data.edge_index[1], data.x\n",
    "        deg = degree(col, data.num_nodes)\n",
    "\n",
    "        if self.norm:\n",
    "            deg = deg / (deg.max() if self.max is None else self.max)\n",
    "\n",
    "        deg = deg.view(-1, 1)\n",
    "\n",
    "        if x is not None and self.cat:\n",
    "            x = x.view(-1, 1) if x.dim() == 1 else x\n",
    "            data.x = torch.cat([x, deg.to(x.dtype)], dim=-1)\n",
    "        else:\n",
    "            data.x = deg\n",
    "\n",
    "        return data\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}(norm={}, max_value={})'.format(self.__class__.__name__, self.norm, self.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d15dbf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "prot = TUDataset('.', 'PROTEINS', pre_transform=Indegree(), use_node_attr=True, ) # this downloads the PROTEINS data set to the current directory and \n",
    "# and loads it to the variable prot, prot is now a torch_geometric.Dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06bc5ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 162], x=[42, 5], y=[1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prot[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52c55dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNConv_local(gnn.MessagePassing):\n",
    "    # Implementation from troch.geometric\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n",
    "\n",
    "        '''\n",
    "        TODO: implement the GCN layer with a bias according the\n",
    "        equations given.\n",
    "        Arguments:\n",
    "        in_channels: dimension of input\n",
    "        out_channels: dimension of output\n",
    "        '''\n",
    "        ### Start your code here\n",
    "        self.lin = nn.Linear(in_channels, out_channels, bias=False)\n",
    "        self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "        ### End your code\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "        self.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        '''\n",
    "        arguments:\n",
    "        x: the feature matrix of the graph.\n",
    "        x has shape [N, in_channels], where N is the number of nodes\n",
    "        edge_index: the adjacency list of the graph.\n",
    "        edge_index has shape [2, E]\n",
    "        '''\n",
    "\n",
    "        ### TODO: implement the forward pass\n",
    "        # Step 1: Add self-loops to the adjacency matrix.\n",
    "        # hint, we imported an add_self_loops function.\n",
    "\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: Apply the linear transofmration.\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        \n",
    "        # Step 3: Compute the normalized Laplacian.\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # Step 4-5: Propagate messages\n",
    "        out = self.propagate(edge_index, x=x, norm=norm)\n",
    "\n",
    "        # Step 6: Apply the bias\n",
    "        out += self.bias\n",
    "\n",
    "        ###END TODO\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # x_j has shape [E, out_channels]\n",
    "        \n",
    "        # Step 4: Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "149a3a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.conv1 = GCNConv(num_features, 32)\n",
    "        self.conv2 = GCNConv(32, 32)\n",
    "        self.conv3 = GCNConv(32, 32)\n",
    "        self.conv4 = GCNConv(32, 1)\n",
    "        self.conv5 = Conv1d(1, 16, 97, 97)\n",
    "        self.conv6 = Conv1d(16, 32, 5, 1)\n",
    "        self.pool = MaxPool1d(2, 2)\n",
    "        self.classifier_1 = Linear(352, 128)\n",
    "        self.drop_out = Dropout(0.5)\n",
    "        self.classifier_2 = Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        edge_index, _ = remove_self_loops(edge_index)\n",
    "\n",
    "        x_1 = torch.tanh(self.conv1(x, edge_index))\n",
    "        x_2 = torch.tanh(self.conv2(x_1, edge_index))\n",
    "        x_3 = torch.tanh(self.conv3(x_2, edge_index))\n",
    "        x_4 = torch.tanh(self.conv4(x_3, edge_index))\n",
    "        x = torch.cat([x_1, x_2, x_3, x_4], dim=-1)\n",
    "        x = global_sort_pool(x, batch, k=30)\n",
    "        x = x.view(x.size(0), 1, x.size(-1))\n",
    "        x = self.relu(self.conv5(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv6(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        out = self.relu(self.classifier_1(x))\n",
    "        out = self.drop_out(out)\n",
    "        classes = F.log_softmax(self.classifier_2(out), dim=-1)\n",
    "\n",
    "        return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72635952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
